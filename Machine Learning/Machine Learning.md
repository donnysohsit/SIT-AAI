# Machine Learning
![Logo](imgs/Header.jpg)
## Definitions to know beforehand

Activation Function: An activation function is a mathematical operation applied to each node (or neuron) in a neural network. It
determines the output of a neuron, enabling the network to capture complex patterns in the data. Activation functions
introduce non-linearities to the model, allowing it to learn and approximate more intricate relationships within the input data.
Common activation functions include the sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), and variants.

Perceptron: A perceptron is the simplest form of a neural network. It is a single-layer, feedforward neural network with on
layer of input nodes, each connected to a single output node. The perceptron takes multiple input features, each multiplied by a
weight, sums up these weighted inputs, adds a bias, and applies an activation function to produce an output.

Neural Network: A neural network is a computational model inspired by the human brain's structure and functioning. It consists
of interconnected nodes, also known as neurons or perceptrons, organized into layers. Neural networks are capable of learning
and approximating complex mappings from input data to output predictions. In a feedforward neural network, information
flows from the input layer through one or more hidden layers to the output layer. Training a neural network involves adjusting
the weights and biases associated with connections between nodes to minimize the difference between predicted and actual
outputs.

## Google Collab Examples
### Neural Network Examples
+ Perceptron model [Perceptron Model](https://colab.research.google.com/drive/1yuTOJS6QuggzjspFUyTLwPNOxP8AJVOi?usp=sharing#scrollTo=PtPAQ1jGpyBM)
+ Single layer perceptron model [Single Layer Perceptron Model](https://colab.research.google.com/drive/1gEbZ3JRHlSoeMqIZ9ckFak5KbWU4sSlb?usp=sharing#scrollTo=PtPAQ1jGpyBM)
+ Multi layer perceptron model [Multi Layer Perceptron Model](https://colab.research.google.com/drive/1FnmGiz4ZFOghLZGGNuGivXFAwjWR45-8?usp=sharing)